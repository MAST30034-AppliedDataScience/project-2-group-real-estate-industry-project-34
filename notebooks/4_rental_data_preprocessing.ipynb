{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate agency IDs found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Directories\n",
    "json_dir = \"../data/landing/\"\n",
    "json_dir_new = \"../data/landing/new/\"\n",
    "\n",
    "# Function to extract agency IDs from filenames\n",
    "def extract_agency_id(filename):\n",
    "    # Assuming filenames follow the pattern \"listings_agency_<agency_id>.json\" or similar\n",
    "    match = re.search(r'listings_agency_(\\d+)', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "# List all JSON files in both directories\n",
    "json_files = [f for f in os.listdir(json_dir) if f.endswith('.json')]\n",
    "json_files_new = [f for f in os.listdir(json_dir_new) if f.endswith('.json')]\n",
    "\n",
    "# Extract agency IDs from filenames in both directories\n",
    "agency_ids_landing = set(filter(None, [extract_agency_id(f) for f in json_files]))\n",
    "agency_ids_new = set(filter(None, [extract_agency_id(f) for f in json_files_new]))\n",
    "\n",
    "# Find duplicates by checking for common agency IDs between the two directories\n",
    "duplicate_agency_ids = agency_ids_landing.intersection(agency_ids_new)\n",
    "\n",
    "# Output results\n",
    "if duplicate_agency_ids:\n",
    "    print(f\"Duplicate agency IDs found: {duplicate_agency_ids}\")\n",
    "else:\n",
    "    print(\"No duplicate agency IDs found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating 112 DataFrames from the old directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Function to load a JSON file into a DataFrame\n",
    "def load_json_to_df(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return pd.json_normalize(data)\n",
    "\n",
    "# Directory containing the JSON files (Old Directory)\n",
    "json_dir = \"../data/landing/\"\n",
    "\n",
    "# List all JSON files in the old directory\n",
    "json_files = [f for f in os.listdir(json_dir) if f.endswith('.json')]\n",
    "\n",
    "# Initialize list to store DataFrames for the old directory\n",
    "dfs_old = []\n",
    "\n",
    "# Loop through each JSON file in the old directory, load it, and append to dfs_old\n",
    "for json_file in json_files:\n",
    "    file_path = os.path.join(json_dir, json_file)\n",
    "    df = load_json_to_df(file_path)\n",
    "    \n",
    "    # Check if the DataFrame is empty\n",
    "    if not df.empty:\n",
    "        dfs_old.append(df)\n",
    "    else:\n",
    "        print(f\"Skipped empty DataFrame for file: {json_file}\")\n",
    "\n",
    "# Concatenate all DataFrames from the old directory into a single DataFrame\n",
    "print(f\"Concatenating {len(dfs_old)} DataFrames from the old directory\")\n",
    "compiled_df = pd.concat(dfs_old, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective                                      583466\n",
      "propertyTypes                                  583420\n",
      "status                                         583466\n",
      "saleMode                                       583466\n",
      "channel                                        583466\n",
      "                                                ...  \n",
      "advertiserIdentifiers.conjunctionContactIds         6\n",
      "advertiserIdentifiers.conjunctionAgentIds           6\n",
      "saleDetails.tenderDetails.tenderEndDate            18\n",
      "saleDetails.tenantDetails.leaseEndDate              3\n",
      "devProjectId                                        6\n",
      "Length: 99, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(compiled_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recursively convert unhashable types (dict, list) to hashable types (tuple)\n",
    "def make_hashable(item):\n",
    "    if isinstance(item, dict):\n",
    "        return tuple((key, make_hashable(value)) for key, value in sorted(item.items()))\n",
    "    elif isinstance(item, list):\n",
    "        return tuple(make_hashable(i) for i in item)\n",
    "    else:\n",
    "        return item\n",
    "\n",
    "# Load the JSON file into a DataFrame\n",
    "pdf = compiled_df\n",
    "\n",
    "# Apply the recursive conversion to all elements in the DataFrame\n",
    "for col in pdf.columns:\n",
    "    pdf[col] = pdf[col].apply(make_hashable)\n",
    "\n",
    "# Now you can drop duplicates\n",
    "pdf_cleaned = pdf.drop_duplicates()\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(pdf_cleaned.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = compiled_df[compiled_df['objective'] == 'rent']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "objective                                            136047\n",
       "propertyTypes                                        135951\n",
       "status                                               136047\n",
       "saleMode                                             136047\n",
       "channel                                              136047\n",
       "                                                      ...  \n",
       "saleDetails.tenantDetails.tenantInfoTermOfLeaseTo         0\n",
       "saleDetails.tenantDetails.leaseStartDate                  0\n",
       "saleDetails.tenantDetails.leaseEndDate                    0\n",
       "advertiserIdentifiers.conjunctionContactIds               0\n",
       "advertiserIdentifiers.conjunctionAgentIds                 0\n",
       "Length: 98, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "objective                                      389071\n",
       "propertyTypes                                  389048\n",
       "status                                         389071\n",
       "saleMode                                       389071\n",
       "channel                                        389071\n",
       "                                                ...  \n",
       "advertiserIdentifiers.conjunctionContactIds         4\n",
       "advertiserIdentifiers.conjunctionAgentIds           4\n",
       "saleDetails.tenderDetails.tenderEndDate             0\n",
       "saleDetails.tenantDetails.leaseEndDate              0\n",
       "devProjectId                                        0\n",
       "Length: 99, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtered for only apartments and removed carparks as they skew the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_filtered = filtered_df[filtered_df['priceDetails.price'] <= 200]\n",
    "\n",
    "# Select relevant columns for inspection\n",
    "columns_of_interest = ['priceDetails.price', 'propertyTypes', 'headline', 'description', 'addressParts.displayAddress', 'dateListed']\n",
    "\n",
    "# Display the relevant information for these listings\n",
    "print(price_filtered.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(filtered_df['priceDetails.price'], kde=False)  # Let seaborn choose the number of bins automatically\n",
    "# Set x-axis limits\n",
    "plt.xlim(-500, 1400)\n",
    "plt.title('Distribution of Prices')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove the dollar sign and commas\n",
    "filtered_df['priceDetails.displayPrice'] = filtered_df['priceDetails.displayPrice'].str.replace('$', '', regex=False)  # Remove dollar sign\n",
    "filtered_df['priceDetails.displayPrice'] = filtered_df['priceDetails.displayPrice'].str.replace(',', '', regex=False)  # Remove commas\n",
    "\n",
    "# Step 2: Convert the cleaned strings to floats\n",
    "filtered_df['priceDetails.displayPrice'] = pd.to_numeric(filtered_df['priceDetails.displayPrice'], errors='coerce')  # Convert to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the 'priceDetails.price' column\n",
    "missing_values = filtered_df['priceDetails.displayPrice'].isna().sum()\n",
    "print(f\"Number of missing values: {missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  number_of_listings\n",
      "0   2004                1014\n",
      "1   2005                9625\n",
      "2   2006                7955\n",
      "3   2007                8373\n",
      "4   2008                9470\n",
      "5   2009               10318\n",
      "6   2010               12017\n",
      "7   2011               14122\n",
      "8   2012               18799\n",
      "9   2013               20492\n",
      "10  2014               20056\n",
      "11  2015               20848\n",
      "12  2016               20190\n",
      "13  2017               19754\n",
      "14  2018               21910\n",
      "15  2019               23525\n",
      "16  2020               32077\n",
      "17  2021               32010\n",
      "18  2022               30950\n",
      "19  2023               31451\n",
      "20  2024               24115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_413067/1973548176.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['dateListed'] = pd.to_datetime(df['dateListed'])\n",
      "/tmp/ipykernel_413067/1973548176.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['year'] = df['dateListed'].dt.year\n"
     ]
    }
   ],
   "source": [
    "df = filtered_df\n",
    "\n",
    "# Convert 'dateListed' to datetime\n",
    "df['dateListed'] = pd.to_datetime(df['dateListed'])\n",
    "\n",
    "# Extract year from 'dateListed'\n",
    "df['year'] = df['dateListed'].dt.year\n",
    "\n",
    "# Count number of listings per year\n",
    "listings_per_year = df.groupby('year').size().reset_index(name='number_of_listings')\n",
    "\n",
    "# Print results\n",
    "print(listings_per_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "objective                                    152345\n",
       "propertyTypes                                152338\n",
       "status                                       152345\n",
       "saleMode                                     152345\n",
       "channel                                      152345\n",
       "                                              ...  \n",
       "advertiserIdentifiers.conjunctionAgentIds         0\n",
       "saleDetails.tenderDetails.tenderEndDate           0\n",
       "saleDetails.tenantDetails.leaseEndDate            0\n",
       "devProjectId                                      0\n",
       "year                                         152345\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = filtered_df[filtered_df['priceDetails.price'] >= 200]\n",
    "filtered_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Filter out unrealistic numbers of bathrooms and bedrooms\n",
    "filtered_df = filtered_df[(filtered_df['bathrooms'] >= 1) & (filtered_df['bathrooms'] <= 10)]\n",
    "filtered_df = filtered_df[(filtered_df['bedrooms'] >= 1) & (filtered_df['bedrooms'] <= 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "objective                                    151173\n",
       "propertyTypes                                151166\n",
       "status                                       151173\n",
       "saleMode                                     151173\n",
       "channel                                      151173\n",
       "                                              ...  \n",
       "advertiserIdentifiers.conjunctionAgentIds         0\n",
       "saleDetails.tenderDetails.tenderEndDate           0\n",
       "saleDetails.tenantDetails.leaseEndDate            0\n",
       "devProjectId                                      0\n",
       "year                                         151173\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  number_of_listings\n",
      "0   2004                 757\n",
      "1   2005                7667\n",
      "2   2006                6475\n",
      "3   2007                6885\n",
      "4   2008                7839\n",
      "5   2009                5353\n",
      "6   2010                3311\n",
      "7   2011                4612\n",
      "8   2012                8694\n",
      "9   2013                8943\n",
      "10  2014                7623\n",
      "11  2015                7996\n",
      "12  2016                5492\n",
      "13  2017                1710\n",
      "14  2018                3536\n",
      "15  2019               11024\n",
      "16  2020               13583\n",
      "17  2021               10608\n",
      "18  2022                9959\n",
      "19  2023               10577\n",
      "20  2024                8529\n"
     ]
    }
   ],
   "source": [
    "df = filtered_df\n",
    "\n",
    "# Convert 'dateListed' to datetime\n",
    "df['dateListed'] = pd.to_datetime(df['dateListed'])\n",
    "\n",
    "# Extract year from 'dateListed'\n",
    "df['year'] = df['dateListed'].dt.year\n",
    "\n",
    "# Count number of listings per year\n",
    "listings_per_year = df.groupby('year').size().reset_index(name='number_of_listings')\n",
    "\n",
    "# Print results\n",
    "print(listings_per_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "filtered_df.to_parquet('../data/raw/filtered_rental_listings_old.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Parquet file\n",
    "df = pd.read_parquet('../data/raw/filtered_rental_listings.parquet')\n",
    "\n",
    "# Select only the important columns\n",
    "selected_columns = [\n",
    "    'addressParts.displayAddress',  # Full address\n",
    "    'addressParts.stateAbbreviation', \n",
    "    'addressParts.suburb', \n",
    "    'bedrooms',                     # Number of bedrooms\n",
    "    'bathrooms',                    # Number of bathrooms\n",
    "    'propertyTypes',\n",
    "    'carspaces',                    # Number of car spaces\n",
    "    'dateListed',                   # Listing date\n",
    "    'geoLocation.latitude',         # Latitude\n",
    "    'geoLocation.longitude',        # Longitude\n",
    "    'isNewDevelopment',             # New development flag\n",
    "    'priceDetails.price',    # Price of the listing\n",
    "    'propertyId',                    # Property ID\n",
    "    'rentalDetails.leasedDate'      # Leased date\n",
    "]\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Keep only the selected columns\n",
    "selected_df = df[selected_columns]\n",
    "\n",
    "selected_df = selected_df.rename(columns={\n",
    "    'addressParts.displayAddress': 'address',\n",
    "    'addressParts.stateAbbreviation': 'state',\n",
    "    'addressParts.suburb': 'suburb',\n",
    "    'dateListed': 'date_listed',\n",
    "    'geoLocation.latitude': 'latitude',\n",
    "    'geoLocation.longitude': 'longitude',\n",
    "    'isNewDevelopment': 'is_new_development',\n",
    "    'priceDetails.price': 'price',\n",
    "    'rentalDetails.leasedDate': 'leased_date'\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "address               147647\n",
       "state                 147647\n",
       "suburb                147647\n",
       "bedrooms              147647\n",
       "bathrooms             147647\n",
       "propertyTypes         147640\n",
       "carspaces             147647\n",
       "date_listed           147647\n",
       "latitude              142701\n",
       "longitude             142701\n",
       "is_new_development    147647\n",
       "price                 147647\n",
       "propertyId             93827\n",
       "leased_date            52293\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "selected_df = selected_df[selected_df['state'] == \"vic\"]\n",
    "selected_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'dateListed' is in datetime format\n",
    "selected_df['date_listed'] = pd.to_datetime(selected_df['date_listed'])\n",
    "\n",
    "# Extract only the date (without time)\n",
    "selected_df['date_listed'] = selected_df['date_listed'].dt.date\n",
    "\n",
    "# Add columns for year, month, and day\n",
    "selected_df['year'] = pd.DatetimeIndex(selected_df['date_listed']).year\n",
    "selected_df['month'] = pd.DatetimeIndex(selected_df['date_listed']).month\n",
    "selected_df['day'] = pd.DatetimeIndex(selected_df['date_listed']).day\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(selected_df[['date_listed', 'year', 'month', 'day']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert 'date_listed' and 'leased_date' to datetime\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m selected_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_listed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mto_datetime(selected_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_listed\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m selected_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleased_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(selected_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleased_date\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Calculate the number of days the listing was on the market (if leased_date is present)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert 'date_listed' and 'leased_date' to datetime\n",
    "selected_df['date_listed'] = pd.to_datetime(selected_df['date_listed'], errors='coerce')\n",
    "selected_df['leased_date'] = pd.to_datetime(selected_df['leased_date'], errors='coerce')\n",
    "\n",
    "# Calculate the number of days the listing was on the market (if leased_date is present)\n",
    "selected_df['days_on_market'] = (selected_df['leased_date'] - selected_df['date_listed']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, you can save the filtered DataFrame back as Parquet\n",
    "selected_df.to_parquet('../data/curated/feature_selected_rental_listings.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
